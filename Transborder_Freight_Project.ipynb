{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df1abbec-f9de-4c65-bfdf-8962fd4447fe",
   "metadata": {},
   "source": [
    "# U.S. Transborder Freight Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be2519-3943-4342-a4f3-41978471ee9c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9039d105-0833-44cb-80f6-b6a860f5f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96986d62-957e-45a6-9f9d-cf51ef9ebcd4",
   "metadata": {},
   "source": [
    "### File Extraction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2cc1f62-279c-45ce-b4fd-137ba3b8fd18",
   "metadata": {},
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def extract_all_zip_recursive(zip_path, extract_to):\n",
    "    def _extract(zip_path, extract_dir):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "       \n",
    "\n",
    "        for root, _, files in os.walk(extract_dir):\n",
    "            for file in files:\n",
    "                full_path = os.path.join(root, file)\n",
    "                if zipfile.is_zipfile(full_path):\n",
    "                    new_extract_dir = os.path.splitext(full_path)[0]\n",
    "                    os.makedirs(new_extract_dir, exist_ok=True)\n",
    "                    _extract(full_path, new_extract_dir)\n",
    "                    \n",
    "\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    _extract(zip_path, extract_to)\n",
    "\n",
    "\n",
    "# Changing the location of the files to be unzipped\n",
    "zip_file = 'data.zip'\n",
    "output_dir = 'unzipped_project_data'\n",
    "\n",
    "extract_all_zip_recursive(zip_file, output_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6326f75d-3cad-494b-923f-07c8751a3dfd",
   "metadata": {},
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def flatten_csv_files(data_folder):\n",
    "    # Walk through all subdirectories in the data folder\n",
    "    for dirpath, dirnames, filenames in os.walk(data_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith('.csv'):\n",
    "                src_path = os.path.join(dirpath, filename)\n",
    "                dst_path = os.path.join(data_folder, filename)\n",
    "\n",
    "                # Rename file if there's a conflict\n",
    "                if os.path.exists(dst_path):\n",
    "                    base, ext = os.path.splitext(filename)\n",
    "                    counter = 1\n",
    "                    while os.path.exists(dst_path):\n",
    "                        dst_path = os.path.join(data_folder, f\"{base}_{counter}{ext}\")\n",
    "                        counter += 1\n",
    "\n",
    "                shutil.move(src_path, dst_path)\n",
    "\n",
    "    # Remove empty subfolders\n",
    "    for dirpath, dirnames, filenames in os.walk(data_folder, topdown=False):\n",
    "        if dirpath != data_folder and not dirnames and not filenames:\n",
    "            os.rmdir(dirpath)\n",
    "\n",
    "# Path to the unzipped_project_data folder\n",
    "data_folder = r'unzipped_project_data'\n",
    "\n",
    "flatten_csv_files(data_folder)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56fa1f11-ed4d-4694-8b58-f6fbe9364122",
   "metadata": {},
   "source": [
    "def load_multiple_csvs_from_zip(data):\n",
    "    \"\"\"\n",
    "    Loads all CSV files from a ZIP archive into a dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    dataframes = {}\n",
    "\n",
    "    with zipfile.ZipFile(data.zip, 'r') as zip_ref:\n",
    "        # Loop through all files in the ZIP\n",
    "        for filename in zip_ref.namelist():\n",
    "            # Only process .csv files\n",
    "            if filename.endswith('.csv'):\n",
    "                with zip_ref.open(data) as file:\n",
    "                    df = pd.read_csv(data)\n",
    "                    dataframes[data] = df\n",
    "                    print(f\"Loaded {data}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    \n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6342ef8-772d-48db-a30e-e2127871052d",
   "metadata": {},
   "source": [
    "#### directly adding all csvs except concat\n",
    "\n",
    "import os\n",
    "\n",
    "def append_csvs_by_filename_pattern(folder_path):\n",
    "    all_dataframes = []\n",
    "\n",
    "    # Looping through all files in folder and subfolders\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            # Checking for .csv and starts with dot\n",
    "            if filename.lower().endswith('.csv') and filename.startswith('dot'):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, dtype={4: str, 11: str})\n",
    "\n",
    "                    # Tracking file source (optional)\n",
    "                    df['source_file'] = filename\n",
    "\n",
    "                    all_dataframes.append(df)\n",
    "                    print(f\"✔ Loaded: {filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠ Error reading {filename}: {e}\")\n",
    "\n",
    "    # Combining all loaded DataFrames\n",
    "    if all_dataframes:\n",
    "        combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"No matching CSV files found.\")\n",
    "        return None\n",
    "\n",
    "# Path to your 'data' folder\n",
    "data_folder = r'unzipped_project_data'\n",
    "\n",
    "# Run function\n",
    "result_df = append_csvs_by_filename_pattern(data_folder)\n",
    "\n",
    "# Saving result\n",
    "if result_df is not None:\n",
    "    output_file = os.path.join(data_folder, 'all_concat.csv')\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\n Combined CSV saved to:\\n{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c9c0aa-15d1-49bc-8894-ab448567f00a",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m freight_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munzipped_project_data/all_concat.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_bad_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mskip\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m freight_data.head(\u001b[32m5\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:252\u001b[39m, in \u001b[36mPythonParser.read\u001b[39m\u001b[34m(self, rows)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\n\u001b[32m    247\u001b[39m     \u001b[38;5;28mself\u001b[39m, rows: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    248\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\n\u001b[32m    249\u001b[39m     Index | \u001b[38;5;28;01mNone\u001b[39;00m, Sequence[Hashable] | MultiIndex, Mapping[Hashable, ArrayLike]\n\u001b[32m    250\u001b[39m ]:\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m         content = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    254\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._first_chunk:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:1144\u001b[39m, in \u001b[36mPythonParser._get_lines\u001b[39m\u001b[34m(self, rows)\u001b[39m\n\u001b[32m   1141\u001b[39m             rows += \u001b[32m1\u001b[39m\n\u001b[32m   1143\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m next_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1144\u001b[39m                 \u001b[43mnew_rows\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_row\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1145\u001b[39m         len_new_rows = \u001b[38;5;28mlen\u001b[39m(new_rows)\n\u001b[32m   1147\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[31mMemoryError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "freight_data = pd.read_csv('unzipped_project_data/all_concat.csv',engine='python', on_bad_lines='skip')\n",
    "freight_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5196af-5169-48d5-9cf7-4e6459203e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping source_file column\n",
    "freight_data = freight_data.drop(columns=['source_file'])\n",
    "\n",
    "# Combining Year and Month into a datetime column\n",
    "freight_data['DATE'] = pd.to_datetime(freight_data['YEAR'].astype(str) + '-' + freight_data['MONTH'].astype(str))\n",
    "\n",
    "# Sorting by date\n",
    "freight_data = freight_data.sort_values('DATE')\n",
    "freight_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c3479-13fd-4d82-9f60-1969020f80b3",
   "metadata": {},
   "source": [
    "## Business Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e8267-10d2-4660-841b-fb7279d36337",
   "metadata": {},
   "source": [
    "#### 1.\tWhat are the overall trends in freight volume and value or revenue over time? \n",
    "#### 2.\tWhich transport mode (truck, rail, pipeline, air, vessel) dominated in terms of weight and value? \n",
    "#### 3.\tHow did trade values evolve per country (U.S.–Canada vs. U.S.–Mexico)? \n",
    "#### 4.\tWhich ports of entry consistently handled the highest number of shipments? \n",
    "#### 5.\tWhat were the top commodity types traded with each country? \n",
    "#### 6.\tWhat was the total number of shipments and value made across the years? \n",
    "#### 7.\tWhich freight modes had higher freight charges on average? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f9b82f-83ad-44c7-b3f3-b01bae1e75ed",
   "metadata": {},
   "source": [
    "### 1. Overall trends in freight volume and value over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef30a9-5518-4e31-8dc3-a3c50230b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "df = pd.read_csv(\"transborder_freight.csv\", parse_dates=['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "\n",
    "# Value/Weight Over Time\n",
    "trend = df.groupby('Year')[['Value', 'Weight']].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=trend, x='Year', y='Value', label='Total Value', color='steelblue')\n",
    "sns.lineplot(data=trend, x='Year', y='Weight', label='Total Weight', color='skyblue')\n",
    "\n",
    "# Data labels\n",
    "for x, y in zip(trend['Year'], trend['Value']):\n",
    "    plt.text(x, y, f'{y/1e9:.1f}B', ha='center', va='bottom', fontsize=9, color='steelblue')\n",
    "\n",
    "for x, y in zip(trend['Year'], trend['Weight']):\n",
    "    plt.text(x, y, f'{y/1e6:.1f}M', ha='center', va='top', fontsize=9, color='skyblue')\n",
    "\n",
    "plt.title(\"Freight Volume & Value Over Time\")\n",
    "plt.ylabel(\"Total Value / Weight\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249dbcc5-f948-4534-9786-e2f1e8dfd6be",
   "metadata": {},
   "source": [
    "### 2. Transport mode dominance by weight and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01d075-b317-4960-bf1e-d93bda1ca7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map modes for readability\n",
    "df['mode_mapped'] = df['Mode'].map({\n",
    "    'Truck': 'Truck', 'Rail': 'Rail', 'Air': 'Air', 'Pipeline': 'Pipeline', 'Vessel': 'Vessel'\n",
    "})\n",
    "\n",
    "mode_summary = df.groupby('mode_mapped')[['Value', 'Weight']].sum().reset_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(data=mode_summary, x='mode_mapped', y='Value', palette='Blues_d')\n",
    "\n",
    "# Data labels\n",
    "for container in barplot.containers:\n",
    "    barplot.bar_label(container, labels=[f'{v.get_height()/1e9:.1f}B' for v in container])\n",
    "\n",
    "plt.title(\"Freight Value by Transport Mode\")\n",
    "plt.ylabel(\"Value (in USD)\")\n",
    "plt.xlabel(\"Transport Mode\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb56f69-1698-4eb5-ba6f-5b44bb678c23",
   "metadata": {},
   "source": [
    "### 3. Trade Value Trend by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02828b84-6231-409d-a45c-8171964ddd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country_mapped'] = df['Country'].map({\n",
    "    'Canada': 'Canada',\n",
    "    'Mexico': 'Mexico'\n",
    "})\n",
    "\n",
    "country_trend = df.groupby(['Year', 'country_mapped'])['Value'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=country_trend, x='Year', y='Value', hue='country_mapped', palette='PuBu_d')\n",
    "\n",
    "plt.title(\"Trade Value Over Time: Canada vs Mexico\")\n",
    "plt.ylabel(\"Trade Value (USD)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.legend(title='Country')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d69203-81f1-4a56-a855-4990ffd4d961",
   "metadata": {},
   "source": [
    "### 4. Top ports by shipment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92095f-5bc2-4f47-b9c4-977a066790f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ports = df.groupby('Port')['Shipments'].sum().nlargest(10).reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "barplot = sns.barplot(data=top_ports, x='Port', y='Shipments', palette='Blues_d')\n",
    "\n",
    "# Add labels\n",
    "barplot.bar_label(barplot.containers[0], padding=3)\n",
    "\n",
    "plt.title(\"Top 10 Ports by Shipments\")\n",
    "plt.ylabel(\"Total Shipments\")\n",
    "plt.xlabel(\"Port\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28b058-8417-40e6-a6f3-b3b1448f7af9",
   "metadata": {},
   "source": [
    "### 5. Top commodities per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d96cf9-dc93-48da-8575-7c24081b997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commodity_mapped'] = df['Commodity'].str.title()  # Optional cleanup\n",
    "top_commodities = df.groupby(['country_mapped', 'commodity_mapped'])['Value'].sum().reset_index()\n",
    "top_per_country = top_commodities.sort_values(['country_mapped', 'Value'], ascending=[True, False])\\\n",
    "                                  .groupby('country_mapped').head(5)\n",
    "\n",
    "# Results\n",
    "print(top_per_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f30b7-d02a-43a5-b511-a2709f5c08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"transborder_freight.csv\", parse_dates=['Date'])\n",
    "\n",
    "# Basic country mapping\n",
    "df['country_mapped'] = df['Country'].map({\n",
    "    'Canada': 'Canada',\n",
    "    'Mexico': 'Mexico'\n",
    "})\n",
    "\n",
    "# Get top 5 commodities by value for each country\n",
    "top_commodities = df.groupby(['country_mapped', 'commodity_mapped'])['Value'].sum().reset_index()\n",
    "top_commodities = top_commodities.sort_values(['country_mapped', 'Value'], ascending=[True, False])\n",
    "top_5_per_country = top_commodities.groupby('country_mapped').head(5)\n",
    "\n",
    "# Pivot for stacking\n",
    "pivot = top_5_per_country.pivot(index='country_mapped', columns='commodity_mapped', values='Value').fillna(0)\n",
    "\n",
    "# Plot\n",
    "pivot.plot(kind='bar', stacked=True, colormap='Blues', figsize=(10, 6))\n",
    "\n",
    "# Data labels \n",
    "for i, row in enumerate(pivot.values):\n",
    "    bottom = 0\n",
    "    for j, val in enumerate(row):\n",
    "        if val > 0:\n",
    "            plt.text(i, bottom + val / 2, f'{val/1e9:.1f}B', ha='center', va='center', fontsize=8)\n",
    "            bottom += val\n",
    "\n",
    "\n",
    "plt.title(\"Top 5 Commodities Traded per Country (by Value)\")\n",
    "plt.ylabel(\"Trade Value (USD)\")\n",
    "plt.xlabel(\"Country\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Commodity\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab3f55-337c-4c66-8162-717db0185312",
   "metadata": {},
   "source": [
    "### 6. Total number of shipments and value across all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98a25b-e232-4fa5-8b1a-2bae1f76b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = df[['Shipments', 'Value']].sum()\n",
    "print(f\"Total Shipments: {totals['Shipments']:,}\")\n",
    "print(f\"Total Value: ${totals['Value']/1e9:.2f} Billion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45712a4d-56ca-42fd-a43a-d3fbd20c5bec",
   "metadata": {},
   "source": [
    "### 7. Which freight modes had higher average freight charges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc27d2-2ec1-4590-9600-ecdb3b39a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_avg = df.groupby('mode_mapped')['Freight Charges'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = sns.color_palette(\"Blues\", len(charge_avg))\n",
    "plt.pie(charge_avg, labels=charge_avg.index,\n",
    "        autopct=lambda p: f'{p:.1f}%', startangle=140,\n",
    "        colors=colors, textprops={'fontsize': 11})\n",
    "\n",
    "plt.title(\"Average Freight Charges by Mode\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580e76e-3f92-4f44-a285-bfddabc9526e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad1300-f332-4f8c-a67b-6d40e8bc6a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997cdb0-b61f-48c2-abdb-0b2e661893a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
